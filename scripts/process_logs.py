#########################################################################################################################################
# The script in this file cleans the CSV of metrics outputted by the CSVLogger of train_lm.py
#########################################################################################################################################
import pandas as pd
from pathlib import Path
import argparse

def main():
    # Accepted CLI input arguments
    parser = argparse.ArgumentParser(description="This script cleans a CSV of experiment metrics outputted by `train_lm.py`.")
    parser.add_argument("--metrics-path", type=str, required=True, help="Path to metrics CSV")
    parser.add_argument("--save-dir", type=str, default=None, help="Directory in which to save cleaned CSV file. If omitted, defaults to the same dir as --metrics-path.")
    parser.add_argument("--delete", action='store_true', help="Whether to delete the original metrics CSV file.")

    # Parse the command-line arguments
    args = parser.parse_args()
    metrics_path = args.metrics_path
    save_dir = args.save_dir
    delete = args.delete

    # Ensure that --metrics-path and --save-dir exist
    metrics_path = Path(metrics_path).resolve()
    if not metrics_path.exists():
        raise ValueError(f"The CSV path {metrics_path} does not exist!")
    save_dir = metrics_path.parent if save_dir is None else Path(save_dir).resolve()
    if not save_dir.exists():
        raise ValueError(f"The save directory {save_dir} does not exist!")
    
    # Load the CSV at --metrics-path to store the metrics at step and epoch levels. Find lr column, which 
    # looks like "lr-Optimizer", and may change from experiment to experiment.
    # Also, save columns that store gradient norms in case these help debug diverging runs
    step_metrics = pd.read_csv(metrics_path)
    epoch_metrics = pd.read_csv(metrics_path)
    norm_columns = []
    # lr_columns = []
    for col in step_metrics.columns:
        if 'norm' in col:
            norm_columns.append(col)
        # elif col.startswith('lr-'):
        #     lr_columns.append(col)
    # if not lr_columns:
    #     raise ValueError(f"The CSV {metrics_path} does not contain a learning rate column! Was this generated by `train_lm.py`?")

    # Create the step-level metrics CSV (step, epoch, train loss, and learning rate)
    rows_to_keep = step_metrics['val_loss'].isna() & step_metrics['train_loss_epoch'].isna()  # for pandas, & is elementwise and
    step_metrics = step_metrics.loc[rows_to_keep]
    step_metrics = step_metrics[['step', 'epoch', 'train_loss_step'] + norm_columns] # + lr_columns]
    step_metrics.columns = ['step', 'epoch', 'train_loss'] + norm_columns # + lr_columns
    step_metrics = step_metrics.groupby('step').sum().reset_index()  # for each group, one row has (train_loss_step, epoch) and the other has (lr)
    step_metrics = step_metrics.reindex(sorted(step_metrics.columns), axis=1)  # sort columns to make metrics easier to read
    step_metrics.to_csv(save_dir / 'step_metrics.csv', index=False)

    # Create the epoch-level metrics CSV (epoch, average train loss, and validation loss)
    rows_to_keep = epoch_metrics['val_loss'].notna() | epoch_metrics['train_loss_epoch'].notna()  # for pandas, | is elementwise or
    epoch_metrics = epoch_metrics.loc[rows_to_keep]
    epoch_metrics = epoch_metrics[['epoch', 'train_loss_epoch', 'val_loss']]
    epoch_metrics.columns = ['epoch', 'train_loss', 'val_loss']
    epoch_metrics = epoch_metrics.groupby('epoch').sum().reset_index()  # for each group, one row has (train_loss) and the other has (val_loss)
    epoch_metrics.to_csv(save_dir / 'epoch_metrics.csv', index=False)
    
    # Delete the original CSV if --delete is passed
    if delete:
        metrics_path.unlink()

if __name__ == "__main__":
    main()
    